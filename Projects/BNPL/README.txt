Buy Now, Pay Later (BNPL) is the financial service of purchasing products across short timelines in multiple installments and has over 389,000 active monthly users in Canada as of 2025. Consumer Reports found in the United States, BNPL users “reported poorer financial health than nonusers across a wide variety of factors.” As more Canadians turn to BNPL services, it is imperative for major banks to consider their BNPL clients’ credibility to mitigate loss due to default.

The aim of this project is to compare the majority-recommended classification algorithms of artificial neural networks, LightGBM, random forest, and support vector machines based off the studies and conclusions of Yeh, I.-C., & Lien, C. (2009), Yang, S., & Zhang, H. (2018), Sayjadah, Y. et al, (2018) and Putri et al. (2021) respectively. Additionally, the paper performed a logistic regression model to act as a base model to compare the experimental models against. The paper will use accuracy and model performance as expressed by the AUC value, based on Yang, S., & Zhang, H. (2018) to evaluation the results of the models and identify the best performing.

The original dataset is sourced from Kaggle (bdoey1. (n.d.)) and was transformed into a working dataset, saved in this repository as 'clean_BNPL_python.' EDA was performed in python and R programming, found in the repository. The working dataset can be imported into the 'BNPL_Project' notebook to reproduce results, with execution time possibly varying. 

The results of this paper support the original research question: models used for credit card classification can be applied to BNPL datasets and can be accurate in their prediction. The logistic regression, SVM, and LightGBM models returned accuracyes over 90% and AUC values around 0.76. Random forest returned an 86% accuracy and AUC value averaging 0.72. Neural network performed the worst with a 25% accuracy and a 0.73 and 0.50 AUC value for two models trained on SMOTE resampled and KMeans SMOTE resampled data, respectively. Neural network and random forest, however, have the strongest recall values for the default target class; logistic regression, SVM, and LightGBM all had recall values for the default target variable below 20%.

Original dataset can be found at: https://www.kaggle.com/datasets/bdoey1/bnpl-data-v1?resource=download
