{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPbKQCkCsj6L",
        "outputId": "55885afa-97c4-4e19-8947-46cbd4a12bd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"11.0.28\" 2025-07-15\n",
            "OpenJDK Runtime Environment (build 11.0.28+6-post-Ubuntu-1ubuntu122.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.28+6-post-Ubuntu-1ubuntu122.04.1, mixed mode, sharing)\n"
          ]
        }
      ],
      "source": [
        "#confirm java is running\n",
        "!java -version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install pyspark\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf_7x3lDsyg8",
        "outputId": "2b93a8ff-d7bf-48a5-e83d-0c23591d7266"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import relevant packages\n",
        "import os\n",
        "import json\n",
        "\n",
        "from pyspark.context import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, LongType, TimestampType\n",
        "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import StandardScaler, StringIndexer, VectorAssembler, VectorIndexer, OneHotEncoder\n",
        "from pyspark.ml import pipeline\n",
        "from pyspark.ml.linalg import DenseVector\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tabulate import tabulate\n",
        "import gc\n",
        "from sklearn.datasets import load_iris\n",
        "import csv"
      ],
      "metadata": {
        "id": "i0zYfVrNs6Od"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#start a session\n",
        "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()"
      ],
      "metadata": {
        "id": "0KVjmaSZmE-m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sparkContext.setLogLevel('INFO')"
      ],
      "metadata": {
        "id": "g2eo0gkHus_E"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hDrYTzPruwjO",
        "outputId": "6ec7340a-3513-4b5b-9bda-8232eda7d400"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.5.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformations and Actions"
      ],
      "metadata": {
        "id": "hEGGuTse-VJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using map, flatMap and reduceByKey"
      ],
      "metadata": {
        "id": "4vWeAI5ejbP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#map is used in a one to one context; apply a function to each element of an RDD and return a single element\n",
        "\n",
        "#return the square from 1 to 20:\n",
        "rdd = spark.sparkContext.parallelize(range(1,21))\n",
        "\n",
        "rdd.map(lambda x : x * x).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXcJAO6vjGKp",
        "outputId": "f48c626b-64a7-4eaf-90ea-a853d9af22ef"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 4,\n",
              " 9,\n",
              " 16,\n",
              " 25,\n",
              " 36,\n",
              " 49,\n",
              " 64,\n",
              " 81,\n",
              " 100,\n",
              " 121,\n",
              " 144,\n",
              " 169,\n",
              " 196,\n",
              " 225,\n",
              " 256,\n",
              " 289,\n",
              " 324,\n",
              " 361,\n",
              " 400]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#assume you have a linear relationship between x and y, for each increase of unit 1 for x, y increases by 5:\n",
        "\n",
        "linear_rdd = spark.sparkContext.parallelize(range(1,6))\n",
        "linear_rdd.map(lambda x : x*5).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIGDvFMdj1gn",
        "outputId": "5f2032bd-35f7-4b21-c72c-ea086e9ef781"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 10, 15, 20, 25]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#flatMap will return multiple outputs to one input (a 1 to many relationship). Once used for word count programs.\n",
        "\n",
        "#first, create a text file from a piece of text\n",
        "#the below job description was taken from https://ca.indeed.com/viewjob?jk=0478f9262fd81a1f&tk=1j32golobi9dc8j4&from=serp&vjs=3\n",
        "\n",
        "jobd_text_file = \"\"\"\n",
        "Come make your difference in communities across Canada, where authenticity, trust and making connections is valued – as we shape the future of Canadian retail, together. Our unique position as one of the country's largest employers, coupled with our commitment to positively impact the lives of all Canadians, provides our colleagues a range of opportunities and experiences to help Canadians Live Life Well®.\n",
        "\n",
        "At Companies Limited, we succeed through collaboration and commitment and set a high bar for ourselves and those around us. Whether you are just starting your career, re-entering the workforce, or looking for a new job, this is where you belong.\n",
        "\n",
        "Does working with some of Canada’s most versatile minds in innovation supporting retail, digital consumer solutions and analytical platforms excite you? Company Technology & Analytics powers game-changing retail solutions, giving our customers the ability to live their lives well.\n",
        "\n",
        "Come work with a team that values diverse ideas, prioritizes a culture of inclusion and develops our talent from within. Company Technology & Analytics gives you the chance to excel and helps you to strive for success in a big way. Keep reading to learn more!\n",
        "\n",
        "Article Analyst, Data Operations, (Fixed Term contract)\n",
        "\n",
        "We have an exciting opportunity for an analyst to join our Data Operation Article team. You will play an integral role in our article setup process, engaging with business partners and participating in projects and initiatives. This position implements processes and governance to ensure data integrity and data standards. The Master Data Analyst will have a primary master data element for which they will be responsible for as well as a secondary element to maintain.\n",
        "\n",
        "What You'll Do:\n",
        "\n",
        "Support & implement established data standards and guidelines that relates to Enterprise Data Policies and Procedures in Article Creation and Article Maintenance\n",
        "Provide store support and conduct work in a timely manner\n",
        "Proactively supervise data accuracy and facilitate required data corrective actions with business owners, like Merchandising Team, Supply Chain, Costing, Vendors and other internal groups\n",
        "Contribute to ideas and actions towards continuous improvement of processes within Master Data and Data Quality\n",
        "Partner in resolving master data discrepancies, SLA (Service Level Agreement) impacts, or other operational challenges affected by master data issues\n",
        "Participate in day-to-day data cleansing activities.\n",
        "Build, modify and improve new and ongoing data reports\n",
        "Maintain good communication with business partners regarding master data requests. Proactively pursue all information required for the completion of work assignments\n",
        "What You Bring:\n",
        "\n",
        "Post-Secondary education in Business or related field, or equivalent related experience\n",
        "Store level retail experience is an asset\n",
        "Must have intermediate to advance Microsoft Office skills\n",
        "Strong written and oral communication skills are required\n",
        "Strong analytical and systems thinking skills\n",
        "Ability to work independently and proactively\n",
        "Must be detail oriented and highly organized\n",
        "Ability to work in teams, influence others and manage conflict\n",
        "Ability to work based upon specific timelines and dependencies\n",
        "Experience/knowledge with SAP and SQL/Python/R/SAS/Panda/Jupyter is an asset\n",
        "What Company Offers You\n",
        "\n",
        "We offer flexibility and balance, and an environment that sets you up for success no matter where your workspace is located.\n",
        "\n",
        "Here, you will find a phenomenal team to help you achieve your goals as you help us achieve ours! Work in our fast-paced, exciting Technology environment, helping our stores, colleagues and customers every day.\n",
        "\n",
        "Company colleagues also enjoy:\n",
        "\n",
        "On-site Basketball & Volleyball courts,, Dry Cleaning services (1PCC Office)\n",
        "Paid Vacation\n",
        "If you’re up to the challenge, then we would love to hear from you. Apply today, and get the process started.\n",
        "\n",
        "At Company, we respect the environment, source products with integrity and make a positive difference in the community. Our CORE Values – Care, Ownership, Respect and Excellence – guide all our decision-making and come to life through our Blue Culture. We offer our colleagues progressive careers, comprehensive training, flexibility, and other competitive benefits – these are some of the many reasons why we are one of Canada’s Top Employers.\n",
        "\n",
        "Company recognizes Canada's diversity as a source of national pride and strength. We have made it a priority to reflect our nation’s evolving diversity in the products we sell, the people we hire, and the culture we create in our organization. At Company, we celebrate diversity where differences are valued and supported. Commitment to being an equal opportunity employer is a priority to us, and we encourage people from all backgrounds and identities to apply to our jobs.\n",
        "\n",
        "Accommodation in the recruitment, assessment, and hiring process is available upon request for applicants with disabilities.\n",
        "\n",
        "We thank all candidates for their interest but please note, those candidates who meet the minimum requirements for the position will be contacted.\n",
        "\n",
        "Our commitment to Sustainability and Social Impact is an essential part of the way we do business, and we focus our attention on areas where we can have the greatest impact. Our approach to sustainability and social impact is based on three pillars – Environment, Sourcing and Community – and we are constantly looking for ways to demonstrate leadership in these important areas. Our CORE Values – Care, Ownership, Respect and Excellence – guide all our decision-making and come to life through our Blue Culture. We offer our colleagues progressive careers, comprehensive training, flexibility, and other competitive benefits – these are some of the many reasons why we are one of Canada’s Top Employers, Canada’s Best Diversity Employers, Canada’s Greenest Employers & Canada’s Top Employers for Young People.\n",
        "\n",
        "If you are unsure whether your experience matches every requirement above, we encourage you to apply anyway. We are looking for varied perspectives which include diverse experiences that we can add to our team.\n",
        "\n",
        "We have a long-standing focus on diversity, equity and inclusion because we know it will make our company a better place to work and shop. We are committed to creating accessible environments for our colleagues, candidates and customers. Requests for accommodation due to a disability (which may be visible or invisible, temporary or permanent) can be made at any stage of application and employment. We encourage candidates to make their accommodation needs known so that we can provide equitable opportunities.\n",
        "\n",
        "Please Note:\n",
        "Candidates who are 18 years or older are required to complete a criminal background check. Details will be provided through the application process.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "M2qKAMd4VlPN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export the text file to csv to work within it in spark\n",
        "\n",
        "with open('job_text_file.txt', 'w', encoding ='unicode-escape') as F:\n",
        "  F.write(jobd_text_file)"
      ],
      "metadata": {
        "id": "HZ6jBzSZXPBK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build a spark session\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "          .master('local')\\\n",
        "          .appName('Word_Count')\\\n",
        "          .getOrCreate()"
      ],
      "metadata": {
        "id": "q6sLXvmmY_ce"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#start the word count app\n",
        "\n",
        "sc = spark.sparkContext\n",
        "\n",
        "#read the text file\n",
        "text_file = sc.textFile('/content/job_text_file.txt')\n",
        "counts = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
        "                            .map(lambda word: (word,1))\\\n",
        "                            .reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "output = counts.collect()"
      ],
      "metadata": {
        "id": "4VAvwMGqZf1x"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count, print the number of words in the text file\n",
        "\n",
        "for word, count in output[:20]:\n",
        "  print(f'{word}: {count}')\n",
        "\n",
        "print('truncated to first 20 observations')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um2m3OHecJYF",
        "outputId": "e6c20557-45ad-48e7-85a2-ee08d5b190a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\nCome: 1\n",
            "make: 4\n",
            "your: 5\n",
            "difference: 2\n",
            "in: 17\n",
            "communities: 1\n",
            "across: 1\n",
            "Canada,: 1\n",
            "where: 5\n",
            "authenticity,: 1\n",
            "trust: 1\n",
            "and: 55\n",
            "making: 1\n",
            "connections: 1\n",
            "is: 9\n",
            "valued: 2\n",
            "\\u2013: 9\n",
            "as: 6\n",
            "we: 19\n",
            "shape: 1\n",
            "truncated to first 20 observations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's identify the top 10 most common words\n",
        "\n",
        "top10 = sorted(output, key=lambda x : x[1], reverse=True)[:10]\n",
        "\n",
        "for word, n in top10:\n",
        "  print(f'{word} : {n}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lIrAJS0hNlc",
        "outputId": "1f27d0aa-8330-458b-8ecc-4ee9366bb45c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "and : 55\n",
            "to : 35\n",
            "the : 22\n",
            "our : 21\n",
            "we : 19\n",
            "a : 18\n",
            "in : 17\n",
            "for : 16\n",
            "of : 15\n",
            "are : 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's export this app into a script which can be executed in a terminal at later times.\n",
        "\n",
        "%%writefile wordcount.py\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  spark = SparkSession.builder\\\n",
        "          .master('local')\\\n",
        "          .appName('Word_Count')\\\n",
        "          .getOrCreate()\n",
        "  sc = spark.sparkContext\n",
        "  sc.setLogLevel(\"ERROR\")\n",
        "\n",
        "  text_file = sc.textFile('/content/job_text_file.txt')\n",
        "\n",
        "  counts = text_file.flatMap(lambda line: line.split()) \\\n",
        "                            .map(lambda word: (word,1))\\\n",
        "                            .reduceByKey(lambda x, y: x + y)\n",
        "  output = counts.collect()\n",
        "\n",
        "  df = spark.createDataFrame(counts, ['word', 'count'])\n",
        "  df.coalesce(1).write.mode(\"overwrite\").csv(\"/content/wordcount_csv\", header = True)\n",
        "\n",
        "  spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dFHGE5SBQm0",
        "outputId": "cb251049-29da-4a53-dbbe-0d3a29e31b40"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing wordcount.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the terminal, run spark-submit and the file path\n",
        "\n",
        "ex: spark-submit /content/wordcount.py\n",
        "\n",
        "The program will execute and the output file will appear in the same folder as the file path."
      ],
      "metadata": {
        "id": "pc3AsYFHbXUV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using filter, union, zip, join, distinct, intersect, subtract, etc"
      ],
      "metadata": {
        "id": "oQOViVoC-Y6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#spart a spark session\n",
        "\n",
        "spark = (SparkSession.builder\n",
        "         .appName('Transformations')\n",
        "         .master('local')\n",
        "         .getOrCreate())"
      ],
      "metadata": {
        "id": "ocea0xFV-iNi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a simple UNION ALL of two RDDs\n",
        "\n",
        "firstRdd = spark.sparkContext.parallelize(range(1,6))\n",
        "secondRdd = spark.sparkContext.parallelize(range(6,11))\n",
        "firstRdd.union(secondRdd).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNMv-rmjAjO9",
        "outputId": "fd19e8fe-98a0-42dd-b3a4-fe9d4b15eb05"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#finding the intersection between the two RDDs\n",
        "\n",
        "firstRdd = spark.sparkContext.parallelize(range(1,9))\n",
        "secondRdd = spark.sparkContext.parallelize(range(6,11))\n",
        "firstRdd.intersection(secondRdd).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2WMbw-qAuta",
        "outputId": "d5881ee0-51b3-4dd3-94a3-1945a5614769"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6, 8, 7]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#consider a list of employees and their salaries\n",
        "\n",
        "employeeRDD = spark.sparkContext.parallelize([('Bob'), ('Ashley'), ('Russel'), ('Jessica'),\n",
        "                                              ('Yusef'), ('Ramona'), ('Lenore'), ('Arash')])\n",
        "salaryRDD = spark.sparkContext.parallelize([55000,78000,66000,52000,\n",
        "                                            61000,88000,68000,35000])\n",
        "#we can join via zip\n",
        "employeeRDD.zip(salaryRDD).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7_hqT-5_E3N",
        "outputId": "093df12d-fc32-4bc2-c98c-fad314a24443"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Bob', 55000),\n",
              " ('Ashley', 78000),\n",
              " ('Russel', 66000),\n",
              " ('Jessica', 52000),\n",
              " ('Yusef', 61000),\n",
              " ('Ramona', 88000),\n",
              " ('Lenore', 68000),\n",
              " ('Arash', 35000)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's do some salary filtering\n",
        "\n",
        "emp_sal = employeeRDD.zip(salaryRDD)\n",
        "\n",
        "#salaries over 75k\n",
        "\n",
        "salary75k = emp_sal.filter(lambda x : x[1] >= 75000)\n",
        "salary75k.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZqcg2Y7BSLH",
        "outputId": "a4f61fe3-1c9b-466e-a725-e6aef933f2b0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Ashley', 78000), ('Ramona', 88000)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#salaries less than 55000\n",
        "\n",
        "salary55k = emp_sal.filter(lambda x : x[1] <= 55000)\n",
        "salary55k.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbV9bFD0C4Ku",
        "outputId": "ce2a87b8-ff27-423d-81a1-f1696283e790"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Bob', 55000), ('Jessica', 52000), ('Arash', 35000)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#who has the highest salary?\n",
        "\n",
        "max_sal = emp_sal.sortBy(lambda x : -x[1])\n",
        "max_sal.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFfdPaYmDhFL",
        "outputId": "e5891bf0-ab49-4779-9aa3-74bc874e193c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Ramona', 88000),\n",
              " ('Ashley', 78000),\n",
              " ('Lenore', 68000),\n",
              " ('Russel', 66000),\n",
              " ('Yusef', 61000),\n",
              " ('Bob', 55000),\n",
              " ('Jessica', 52000),\n",
              " ('Arash', 35000)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#consider we have four patients and eight medicines in a double-blind study, what are the possible combinations?\n",
        "\n",
        "patientsRDD = spark.sparkContext.parallelize([('Yusef'), ('Ramona'), ('Lenore'), ('Arash')])\n",
        "medsRDD = spark.sparkContext.parallelize([('A'), ('B'), ('C'), ('D'),('E'), ('F'), ('G'), ('H')])\n",
        "patientsRDD.cartesian(medsRDD).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aanmx0_FD8EU",
        "outputId": "31344835-036c-4c55-e47e-962334155b37"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Yusef', 'A'),\n",
              " ('Yusef', 'B'),\n",
              " ('Yusef', 'C'),\n",
              " ('Yusef', 'D'),\n",
              " ('Yusef', 'E'),\n",
              " ('Yusef', 'F'),\n",
              " ('Yusef', 'G'),\n",
              " ('Yusef', 'H'),\n",
              " ('Ramona', 'A'),\n",
              " ('Ramona', 'B'),\n",
              " ('Ramona', 'C'),\n",
              " ('Ramona', 'D'),\n",
              " ('Ramona', 'E'),\n",
              " ('Ramona', 'F'),\n",
              " ('Ramona', 'G'),\n",
              " ('Ramona', 'H'),\n",
              " ('Lenore', 'A'),\n",
              " ('Lenore', 'B'),\n",
              " ('Lenore', 'C'),\n",
              " ('Lenore', 'D'),\n",
              " ('Lenore', 'E'),\n",
              " ('Lenore', 'F'),\n",
              " ('Lenore', 'G'),\n",
              " ('Lenore', 'H'),\n",
              " ('Arash', 'A'),\n",
              " ('Arash', 'B'),\n",
              " ('Arash', 'C'),\n",
              " ('Arash', 'D'),\n",
              " ('Arash', 'E'),\n",
              " ('Arash', 'F'),\n",
              " ('Arash', 'G'),\n",
              " ('Arash', 'H')]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning & Working With Iris Dataset"
      ],
      "metadata": {
        "id": "xaaKwGdC9ZaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#build a spark session\n",
        "spark = (SparkSession.builder\n",
        "         .appName('Spark Machine Learning')\n",
        "         .config('spark.executor.memory', '1G')\n",
        "         .config('spark.executor.cores', '4')\n",
        "         .getOrCreate())"
      ],
      "metadata": {
        "id": "UihOEXp-tly_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the data & export to CSV\n",
        "iris = load_iris()\n",
        "\n",
        "iris_df = pd.DataFrame(\n",
        "    data = iris.data,\n",
        "    columns = iris.feature_names\n",
        ")\n",
        "\n",
        "iris_df['species'] = iris.target\n",
        "\n",
        "iris_df['species_name'] = iris_df['species'].apply(lambda x: iris.target_names[x])\n",
        "\n",
        "iris_df.to_csv(\"iris.csv\", index = False)"
      ],
      "metadata": {
        "id": "mHeua8zNwQGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the data for spark\n",
        "url = '/content/iris.csv'\n",
        "\n",
        "data = spark.read.format('csv')\\\n",
        "      .option(\"header\", \"true\")\\\n",
        "      .option(\"inferSchema\", \"true\")\\\n",
        "      .load(url)\n",
        "\n",
        "data.cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvZjWqTXuzRr",
        "outputId": "f7736f42-c59a-492a-ea0c-ff2cd540e4d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[sepal length (cm): double, sepal width (cm): double, petal length (cm): double, petal width (cm): double, species: int, species_name: string]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tally observations\n",
        "data.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pE09tKryIan",
        "outputId": "5423731c-5078-462a-c4aa-66186b3ea695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the schema\n",
        "data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2ALPwldyM_X",
        "outputId": "e0683a90-ec6e-474c-97be-ac54d87ae68c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- sepal length (cm): double (nullable = true)\n",
            " |-- sepal width (cm): double (nullable = true)\n",
            " |-- petal length (cm): double (nullable = true)\n",
            " |-- petal width (cm): double (nullable = true)\n",
            " |-- species: integer (nullable = true)\n",
            " |-- species_name: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4bJaCOFyPHf",
        "outputId": "0d600548-29cd-478e-e067-0ecf1faa1430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----------------+-----------------+----------------+-------+------------+\n",
            "|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|species|species_name|\n",
            "+-----------------+----------------+-----------------+----------------+-------+------------+\n",
            "|              5.1|             3.5|              1.4|             0.2|      0|      setosa|\n",
            "|              4.9|             3.0|              1.4|             0.2|      0|      setosa|\n",
            "|              4.7|             3.2|              1.3|             0.2|      0|      setosa|\n",
            "|              4.6|             3.1|              1.5|             0.2|      0|      setosa|\n",
            "|              5.0|             3.6|              1.4|             0.2|      0|      setosa|\n",
            "+-----------------+----------------+-----------------+----------------+-------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tally by species\n",
        "data.groupBy('species').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jupStOTxySSO",
        "outputId": "e81692f0-0fd4-4084-aa81-fee7f4f29982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|species|count|\n",
            "+-------+-----+\n",
            "|      1|   50|\n",
            "|      2|   50|\n",
            "|      0|   50|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#summary statistics of the data\n",
        "data.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufhGFd2-yeg1",
        "outputId": "1028a14c-3603-4212-9a0f-022ba8c5581c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-------------------+------------------+------------------+------------------+------------+\n",
            "|summary| sepal length (cm)|   sepal width (cm)| petal length (cm)|  petal width (cm)|           species|species_name|\n",
            "+-------+------------------+-------------------+------------------+------------------+------------------+------------+\n",
            "|  count|               150|                150|               150|               150|               150|         150|\n",
            "|   mean| 5.843333333333335|  3.057333333333334|3.7580000000000027| 1.199333333333334|               1.0|        NULL|\n",
            "| stddev|0.8280661279778637|0.43586628493669793|1.7652982332594662|0.7622376689603467|0.8192319205190406|        NULL|\n",
            "|    min|               4.3|                2.0|               1.0|               0.1|                 0|      setosa|\n",
            "|    max|               7.9|                4.4|               6.9|               2.5|                 2|   virginica|\n",
            "+-------+------------------+-------------------+------------------+------------------+------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the data was loaded with species already converted to numerics\n",
        "#the following showcases use of StringIndexer to make a new column\n",
        "\n",
        "SIndexer = StringIndexer(inputCol='species', outputCol='species_index')\n",
        "data_sample = SIndexer.fit(data).transform(data)\n",
        "\n",
        "data_sample.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3SYSOboyyrw",
        "outputId": "fd9c3878-97cd-490f-c648-9bd30b59e49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----------------+-----------------+----------------+-------+------------+-------------+\n",
            "|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|species|species_name|species_index|\n",
            "+-----------------+----------------+-----------------+----------------+-------+------------+-------------+\n",
            "|              5.1|             3.5|              1.4|             0.2|      0|      setosa|          0.0|\n",
            "|              4.9|             3.0|              1.4|             0.2|      0|      setosa|          0.0|\n",
            "|              4.7|             3.2|              1.3|             0.2|      0|      setosa|          0.0|\n",
            "|              4.6|             3.1|              1.5|             0.2|      0|      setosa|          0.0|\n",
            "|              5.0|             3.6|              1.4|             0.2|      0|      setosa|          0.0|\n",
            "+-----------------+----------------+-----------------+----------------+-------+------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#confirm column names\n",
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k49DBbPDzpa3",
        "outputId": "77424962-0128-4b84-c53c-747909bf93a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal length (cm)',\n",
              " 'sepal width (cm)',\n",
              " 'petal length (cm)',\n",
              " 'petal width (cm)',\n",
              " 'species',\n",
              " 'species_name']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove flower names\n",
        "df = data.select(\"species\", \"sepal length (cm)\", \"sepal width (cm)\", \"petal length (cm)\", \"petal width (cm)\")\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbLJvWdkzYja",
        "outputId": "a3c489b4-0471-48d4-d333-30fa388513a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+----------------+-----------------+----------------+\n",
            "|species|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|\n",
            "+-------+-----------------+----------------+-----------------+----------------+\n",
            "|      0|              5.1|             3.5|              1.4|             0.2|\n",
            "|      0|              4.9|             3.0|              1.4|             0.2|\n",
            "|      0|              4.7|             3.2|              1.3|             0.2|\n",
            "|      0|              4.6|             3.1|              1.5|             0.2|\n",
            "|      0|              5.0|             3.6|              1.4|             0.2|\n",
            "+-------+-----------------+----------------+-----------------+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define the species column as a dense vector (e.g. label) for the future models\n",
        "\n",
        "input_data = df.rdd.map(lambda x: (x[0], DenseVector(x[1:])))"
      ],
      "metadata": {
        "id": "ifztM8Toz9je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a dataframe holding the labels and features\n",
        "df_index = spark.createDataFrame(input_data, ['label', 'features'])"
      ],
      "metadata": {
        "id": "GJvg1ClC0RmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_index.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLOYGv4f0dWX",
        "outputId": "f58c247d-ba08-402b-f403-5ee05416bcff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+\n",
            "|label|         features|\n",
            "+-----+-----------------+\n",
            "|    0|[5.1,3.5,1.4,0.2]|\n",
            "|    0|[4.9,3.0,1.4,0.2]|\n",
            "|    0|[4.7,3.2,1.3,0.2]|\n",
            "|    0|[4.6,3.1,1.5,0.2]|\n",
            "|    0|[5.0,3.6,1.4,0.2]|\n",
            "+-----+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling to normalize the data\n",
        "\n",
        "stdScaler = StandardScaler(inputCol = \"features\", outputCol = \"features_scaled\")\n",
        "\n",
        "scaler = stdScaler.fit(df_index)\n",
        "\n",
        "df_scaler = scaler.transform(df_index)\n",
        "\n",
        "df_scaler.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgvz2ABu0mWU",
        "outputId": "340c92cd-9630-421d-9316-8ffaee314936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+--------------------+\n",
            "|label|         features|     features_scaled|\n",
            "+-----+-----------------+--------------------+\n",
            "|    0|[5.1,3.5,1.4,0.2]|[6.15892840883878...|\n",
            "|    0|[4.9,3.0,1.4,0.2]|[5.9174018045706,...|\n",
            "|    0|[4.7,3.2,1.3,0.2]|[5.67587520030241...|\n",
            "|    0|[4.6,3.1,1.5,0.2]|[5.55511189816831...|\n",
            "|    0|[5.0,3.6,1.4,0.2]|[6.03816510670469...|\n",
            "+-----+-----------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_scaled = df_scaler.drop(\"features\")"
      ],
      "metadata": {
        "id": "O8iHkpyW1skv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train / test split the model\n",
        "\n",
        "train_data, test_data = df_scaled.randomSplit([0.8, 0.2], seed = 123)"
      ],
      "metadata": {
        "id": "eAAgpAxR2M_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKC5eo1f2ZGo",
        "outputId": "53547566-7e71-4726-aaf6-899d2be29191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|     features_scaled|\n",
            "+-----+--------------------+\n",
            "|    0|[5.19282199176603...|\n",
            "|    0|[5.31358529390013...|\n",
            "|    0|[5.31358529390013...|\n",
            "|    0|[5.43434859603422...|\n",
            "|    0|[5.55511189816831...|\n",
            "+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning"
      ],
      "metadata": {
        "id": "lcT2RvmM9UdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#build ML models\n",
        "\n",
        "model = ['Decision Tree', 'Random Forest', 'Naive Bayes']\n",
        "model_results = []"
      ],
      "metadata": {
        "id": "pDi5UlV02ctu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#decision tree\n",
        "\n",
        "decision_tree = DecisionTreeClassifier(labelCol = \"label\", featuresCol = \"features_scaled\")\n",
        "\n",
        "tree_model = decision_tree.fit(train_data)\n",
        "\n",
        "tree_predict = tree_model.transform(test_data)\n",
        "\n",
        "#evaluate the model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = \"prediction\", metricName = \"accuracy\")\n",
        "\n",
        "model_accuracy = evaluator.evaluate(tree_predict)\n",
        "\n",
        "model_results.extend([[model[0], '{:.2}'.format(model_accuracy)]])"
      ],
      "metadata": {
        "id": "kY_-cwlJ2oJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#random forest\n",
        "\n",
        "random_forest = RandomForestClassifier(labelCol = \"label\", featuresCol=\"features_scaled\")\n",
        "\n",
        "forest_model = random_forest.fit(train_data)\n",
        "\n",
        "forest_predict = forest_model.transform(test_data)\n",
        "\n",
        "#evaluate the model\n",
        "rf_evaluator = MulticlassClassificationEvaluator(labelCol = 'label', predictionCol = 'prediction', metricName = 'accuracy')\n",
        "\n",
        "rf_model_accuracy = rf_evaluator.evaluate(forest_predict)\n",
        "\n",
        "model_results.extend([[model[1], '{:.2}'.format(rf_model_accuracy)]])"
      ],
      "metadata": {
        "id": "S6r-MciZ4hk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive Bayes\n",
        "\n",
        "nv_bayes = NaiveBayes(smoothing = 1.0, modelType = \"multinomial\", labelCol = \"label\", featuresCol=\"features_scaled\")\n",
        "\n",
        "nbayes_model = nv_bayes.fit(train_data)\n",
        "\n",
        "nbayes_predict = nbayes_model.transform(test_data)\n",
        "\n",
        "#evaluate model\n",
        "\n",
        "nv_evaluation = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = 'prediction', metricName = \"accuracy\")\n",
        "\n",
        "nv_model_accuracy = nv_evaluation.evaluate(nbayes_predict)\n",
        "\n",
        "model_results.extend([[model[2], '{:.2}'.format(nv_model_accuracy)]])"
      ],
      "metadata": {
        "id": "x87LdfpF6E9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT6kZCAI8D4P",
        "outputId": "cef9e10e-20a8-4baf-956c-a6e5354f36df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "867"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tabulate(model_results, headers=['Classifier Models', 'Accuracy']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w-DAoAJ8HNo",
        "outputId": "e37db742-ff85-423d-f398-7bf7d5ec2926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier Models      Accuracy\n",
            "-------------------  ----------\n",
            "Decision Tree              0.93\n",
            "Random Forest              0.97\n",
            "Naive Bayes                0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with Big Data"
      ],
      "metadata": {
        "id": "Pa-ywyMj9niB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we'll download a large dataset of Amazon reviews using curl\n",
        "\n",
        "!curl -O https://mcauleylab.ucsd.edu/public_datasets/data/amazon_2023/raw/review_categories/Automotive.jsonl.gz\n",
        "!gunzip -f Automotive.jsonl.gz"
      ],
      "metadata": {
        "id": "t4aXS_cw9rRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the data is zipped, how big is it?\n",
        "\n",
        "print(f'The size of the zipped file is: {os.path.getsize(\"/content/Automotive.jsonl\") / (1024 ** 3):.2f} GB')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW_pU433958J",
        "outputId": "3c962f75-3dfa-4729-b6fc-c0819c288088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of the zipped file is: 8.13 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#start a spark session\n",
        "\n",
        "spark = SparkSession.builder.appName(\"AutomotiveData\").getOrCreate()\n",
        "\n",
        "print(f'The Spark Version is {spark.version}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqEHtk9XA4nv",
        "outputId": "068de177-b380-4500-ae39-a7ad3c114fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Spark Version is 3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's try reading the data via pandas\n",
        "\n",
        "test_df = pd.read_json('/content/Automotive.jsonl', lines = True)\n",
        "print(test_df)"
      ],
      "metadata": {
        "id": "4C-RHLtFBEic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if you run the above code, the session will fail due to all available RAM being used.\n",
        "\n",
        "#clearly, the data is too massive to be handled with conventional packages.\n",
        "\n",
        "#Spark is required!"
      ],
      "metadata": {
        "id": "bI9GqbrkmHlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's confirm the columns of the data\n",
        "\n",
        "with open('/content/Automotive.jsonl', 'r') as file:\n",
        "  line = file.readline()\n",
        "  record = json.loads(line)\n",
        "  print(pd.Series(record))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nkHyOyMnCm-",
        "outputId": "d625637e-e12f-4edf-e60c-6e8c53266f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rating                                                             5.0\n",
            "title                          It fit our 2012 Chevy Colorado perfect!\n",
            "text                 Item came as described! It fit our 2012 Chevy ...\n",
            "images                                                              []\n",
            "asin                                                        B01LZA8SGZ\n",
            "parent_asin                                                 B0BV88374L\n",
            "user_id                                   AGXVBIUFLFGMVLATYXHJYL4A5Q7Q\n",
            "timestamp                                                1513092936205\n",
            "helpful_vote                                                         0\n",
            "verified_purchase                                                 True\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making a PySpark Dataframe\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"rating\", DoubleType(), True),\n",
        "    StructField(\"title\", StringType(), True),\n",
        "    StructField(\"text\", StringType(), True),\n",
        "    StructField(\"images\", StringType(), True),\n",
        "    StructField(\"asin\", StringType(), True),\n",
        "    StructField(\"parent_asin\", StringType(), True),\n",
        "    StructField(\"user_id\", StringType(), True),\n",
        "    StructField(\"timestamp\", TimestampType(), True),\n",
        "    StructField(\"helpful_vote\", IntegerType(), True),\n",
        "    StructField(\"verified_purchase\", IntegerType(), True)\n",
        "])"
      ],
      "metadata": {
        "id": "Ci3UOAALmUjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df = spark.read.schema(schema).json('/content/Automotive.jsonl')"
      ],
      "metadata": {
        "id": "PmMmlz0UqPAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(spark_df.show(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8aTQD7Qqj-d",
        "outputId": "ad68d6fc-0e6f-4742-8e08-14323ecb8dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------------+--------------------+------+----------+-----------+--------------------+--------------------+------------+-----------------+\n",
            "|rating|               title|                text|images|      asin|parent_asin|             user_id|           timestamp|helpful_vote|verified_purchase|\n",
            "+------+--------------------+--------------------+------+----------+-----------+--------------------+--------------------+------------+-----------------+\n",
            "|   5.0|It fit our 2012 C...|Item came as desc...|    []|B01LZA8SGZ| B0BV88374L|AGXVBIUFLFGMVLATY...|+49918-01-03 17:2...|           0|             NULL|\n",
            "|   5.0|    Easy to put on!!|Ease of applicati...|    []|B0B2WGS5ND| B0B2WGS5ND|AFE337D2J37YRU5U6...|+54545-07-22 13:5...|           0|             NULL|\n",
            "|   5.0|             Perfect|Nice quality, fra...|    []|B00A0GV20Q| B00A0GV20Q|AEVWAM3YWN5URJVJI...|+45975-02-05 15:4...|           0|             NULL|\n",
            "|   2.0|      Not waterproof|Description said ...|    []|B08C27WWVG| B08C27WWVG|AHITBJSS7KYUBVZPX...|+54313-07-06 07:0...|           0|             NULL|\n",
            "|   5.0|           Very nice|Looks great on my...|    []|B0719J5ZNY| B0719J5ZNY|AHITBJSS7KYUBVZPX...|+51851-02-25 06:0...|           0|             NULL|\n",
            "+------+--------------------+--------------------+------+----------+-----------+--------------------+--------------------+------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBwyfxGdqurP",
        "outputId": "415b935d-f160-40b0-d6d9-1aac241a91e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- rating: double (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- images: string (nullable = true)\n",
            " |-- asin: string (nullable = true)\n",
            " |-- parent_asin: string (nullable = true)\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- timestamp: timestamp (nullable = true)\n",
            " |-- helpful_vote: integer (nullable = true)\n",
            " |-- verified_purchase: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#depending on resources, the summary statistics make take over 10min to compute\n",
        "spark_df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UfnnGitqyyE",
        "outputId": "fd7796ad-b709-4d55-a510-a701679c43ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+------------------+------------------+\n",
            "|summary|            rating|               title|        text|              images|                asin|         parent_asin|             user_id|      helpful_vote|vertified_purchase|\n",
            "+-------+------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+------------------+------------------+\n",
            "|  count|          19955450|            19955450|    19955450|            19955450|            19955450|            19955450|            19955450|          19955450|                 0|\n",
            "|   mean| 4.182790716320604|                 NaN|    Infinity|                NULL| 4.609848654133604E9| 4.615182888455246E9|                NULL|0.6502186119581368|              NULL|\n",
            "| stddev|1.3815796733887575|                 NaN|         NaN|                NULL|3.8966614041073685E9|3.9923743844483523E9|                NULL| 5.657678307208537|              NULL|\n",
            "|    min|               1.0|                   !|            |                  []|          0010010017|          0010010017|AE2222C2STTMXNUHX...|                -4|              NULL|\n",
            "|    max|               5.0|󾠯󾠯󾠯󾠯󾠯󾠮󾠯󾠰?...|🫶🫶🫶🫶🫶🫶|[{\"small_image_ur...|          b000ie0yiq|          b000ie0yiq|AHZZZZYA4NULLM5PN...|              2822|              NULL|\n",
            "+-------+------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.select(\"title\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr5pP9X423Bo",
        "outputId": "a0f0f909-ed30-4da9-a1b1-9917b5aea404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|               title|\n",
            "+--------------------+\n",
            "|It fit our 2012 C...|\n",
            "|    Easy to put on!!|\n",
            "|             Perfect|\n",
            "|      Not waterproof|\n",
            "|           Very nice|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.filter(spark_df[\"verified_purchase\"].isNull()).count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IctuKgbu3dW1",
        "outputId": "11430069-2572-447c-e4a7-b1878ac38f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19955450"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.select(F.countDistinct(\"verified_purchase\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D11qIc4N5XDZ",
        "outputId": "ad8a421c-a89f-4092-9dfb-a3d75f57464e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------+\n",
            "|count(DISTINCT verified_purchase)|\n",
            "+---------------------------------+\n",
            "|                                0|\n",
            "+---------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.select(\"verified_purchase\").distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRp8LjmR6MwJ",
        "outputId": "390b6eda-7753-4cb7-d1ac-b1129a64c5ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|verified_purchase|\n",
            "+-----------------+\n",
            "|             NULL|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.groupBy('rating').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9p3kwUSubDv",
        "outputId": "43cc10cc-1de9-479b-c08c-d8f724303598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+\n",
            "|rating|   count|\n",
            "+------+--------+\n",
            "|   1.0| 2302427|\n",
            "|   4.0| 2172554|\n",
            "|   3.0| 1185429|\n",
            "|   2.0|  851553|\n",
            "|   5.0|13443487|\n",
            "+------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spark SQL with Amazon Data"
      ],
      "metadata": {
        "id": "IBZzmEzw1D7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#let's run some SQL statements\n",
        "\n",
        "spark_df.createOrReplaceGlobalTempView(\"spark_df\")"
      ],
      "metadata": {
        "id": "ORewX1k5wgqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT rating, helpful_vote \\\n",
        "          FROM global_temp.spark_df \\\n",
        "          WHERE rating >= 4 AND helpful_vote >= 10\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-APkl_GmvbiX",
        "outputId": "87189744-3902-47cc-ea1c-7fc929cfe138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+\n",
            "|rating|helpful_vote|\n",
            "+------+------------+\n",
            "|   5.0|          11|\n",
            "|   5.0|          54|\n",
            "|   5.0|          12|\n",
            "|   5.0|          83|\n",
            "|   4.0|          12|\n",
            "|   4.0|          15|\n",
            "|   5.0|          13|\n",
            "|   5.0|          17|\n",
            "|   4.0|          57|\n",
            "|   4.0|          14|\n",
            "|   5.0|         135|\n",
            "|   4.0|          36|\n",
            "|   5.0|          10|\n",
            "|   5.0|          21|\n",
            "|   5.0|          13|\n",
            "|   5.0|          11|\n",
            "|   5.0|          14|\n",
            "|   5.0|         175|\n",
            "|   5.0|          31|\n",
            "|   5.0|          11|\n",
            "+------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"SELECT title, timestamp, helpful_vote, verified_purchase \\\n",
        "            FROM global_temp.spark_df \\\n",
        "            WHERE verified_purchase IS NULL \\\n",
        "            AND rating <= 2\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wILi3OBxfpg",
        "outputId": "b671c933-9971-4795-f676-652ebcf67a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+------------+------------------+\n",
            "|title|timestamp|helpful_vote|vertified_purchase|\n",
            "+-----+---------+------------+------------------+\n",
            "+-----+---------+------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"SELECT title, timestamp, helpful_vote, verified_purchase \\\n",
        "            FROM global_temp.spark_df \\\n",
        "            WHERE verified_purchase = '1' \\\n",
        "            LIMIT 10\n",
        "            \"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQw_PNVv0W-p",
        "outputId": "c84bc0bd-51a1-4c71-9b02-546493f01e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+------------+------------------+\n",
            "|title|timestamp|helpful_vote|vertified_purchase|\n",
            "+-----+---------+------------+------------------+\n",
            "+-----+---------+------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "          SELECT rating, max(helpful_vote) \\\n",
        "          FROM global_temp.spark_df \\\n",
        "          GROUP BY rating \\\n",
        "          ORDER BY max(helpful_vote) \\\n",
        "          LIMIT 10\n",
        "          \"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlyICHZR0FXw",
        "outputId": "c4ecc066-3e0f-49f0-def7-7f2eedc7913c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------------+\n",
            "|rating|max(helpful_vote)|\n",
            "+------+-----------------+\n",
            "|   2.0|             1514|\n",
            "|   4.0|             1846|\n",
            "|   3.0|             2036|\n",
            "|   1.0|             2134|\n",
            "|   5.0|             2822|\n",
            "+------+-----------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}